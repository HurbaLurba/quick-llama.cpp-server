services:
  # Gemma 3 27B IT Abliterated Vision with ROCm (Linux + GPU access)
  gemma3-27b-it-abliterated-vision-rocm:
    image: ghcr.io/ggml-org/llama.cpp:server-rocm
    container_name: gemma3-27b-it-abliterated-vision-rocm
    ports:
      - "8085:8080"
    # AMD iGPU device access - Toxantron methodology
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    # Group permissions for render and video groups
    group_add:
      - "${RENDER_GROUP_ID:-102}"
      - "${VIDEO_GROUP_ID:-44}"
    # ROCm environment variables for AMD 8945HS (gfx1103)
    environment:
      - HSA_OVERRIDE_GFX_VERSION=11.0.2
      - HCC_AMDGPU_TARGET=gfx1103
      - ROCM_PATH=/opt/rocm
      - HIP_PLATFORM=amd
      - HSA_ENABLE_SDMA=0
      - ROCR_VISIBLE_DEVICES=0
      - HIP_VISIBLE_DEVICES=0
    # Model cache volume
    volumes:
      - llama_cache:/root/.cache/huggingface
    # Start with Gemma 3 model
    command: [
      "--hf-repo", "mlabonne/gemma-3-27b-it-abliterated-GGUF",
      "--hf-file", "gemma-3-27b-it-abliterated-Q4_K_M.gguf",
      "--mmproj", "/root/.cache/huggingface/mlabonne--gemma-3-27b-it-abliterated-GGUF/mmproj-mlabonne_gemma-3-27b-it-abliterated-f16.gguf",
      "--host", "0.0.0.0",
      "--port", "8080",
      "-ngl", "-1",
      "-c", "131072",
      "--flash-attn",
      "--alias", "gemma3-27b-it-abliterated-rocm"
    ]
    restart: unless-stopped

  # Mistral Small 3.2 24B Vision with ROCm (Linux + GPU access)
  mistral-small-3.2-24b-vision-rocm:
    image: ghcr.io/ggml-org/llama.cpp:server-rocm
    container_name: mistral-small-3.2-24b-vision-rocm
    ports:
      - "8085:8080"
    # AMD iGPU device access - Toxantron methodology
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    # Group permissions for render and video groups
    group_add:
      - "${RENDER_GROUP_ID:-102}"
      - "${VIDEO_GROUP_ID:-44}"
    # ROCm environment variables for AMD 8945HS (gfx1103)
    environment:
      - HSA_OVERRIDE_GFX_VERSION=11.0.2
      - HCC_AMDGPU_TARGET=gfx1103
      - ROCM_PATH=/opt/rocm
      - HIP_PLATFORM=amd
      - HSA_ENABLE_SDMA=0
      - ROCR_VISIBLE_DEVICES=0
      - HIP_VISIBLE_DEVICES=0
    # Model cache volume
    volumes:
      - llama_cache:/root/.cache/huggingface
    # Start with Mistral Small model
    command: [
      "--hf-repo", "unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF",
      "--hf-file", "Mistral-Small-3.2-24B-Instruct-2506-UD-Q4_K_XL.gguf",
      "--mmproj", "/root/.cache/huggingface/unsloth--Mistral-Small-3.2-24B-Instruct-2506-GGUF/mmproj-F32.gguf",
      "--host", "0.0.0.0",
      "--port", "8080",
      "-ngl", "-1",
      "-c", "131072",
      "--flash-attn",
      "--reasoning-format", "deepseek",
      "--alias", "mistral-small-3.2-24b-vision-rocm"
    ]
    restart: unless-stopped

volumes:
  llama_cache:
