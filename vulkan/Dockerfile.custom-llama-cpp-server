# Custom LLaMA.cpp Server Container - Multi-Model Support via Scripts (Vulkan)
# Uses official llama.cpp Vulkan server image as base
FROM ghcr.io/ggml-org/llama.cpp:server-vulkan

# Install comprehensive AMD GPU drivers and tools for better hardware detection
RUN apt-get update && apt-get install -y --no-install-recommends \
    # Essential system tools first - these are critical
    pciutils \
    lshw \
    curl \
    wget \
    python3 \
    python3-pip \
    # AMD GPU support - comprehensive Vulkan and OpenCL stack
    mesa-vulkan-drivers \
    libdrm-amdgpu1 \
    # Vulkan tools and validation  
    vulkan-tools \
    libvulkan1 \
    vulkan-validationlayers \
    && rm -rf /var/lib/apt/lists/* \
    # Install huggingface-hub for model downloads (force override system packages)
    && pip3 install --no-cache-dir --break-system-packages huggingface-hub \
    # Ensure DRI device access
    && mkdir -p /dev/dri

# Cache directory for huggingface downloads
ENV LLAMA_CACHE="/root/.cache/llama"

# Default model script (can be overridden at runtime)
ENV MODEL_SCRIPT="mistral-small-3.2-24b-vision-vulkan"

# Enhanced Vulkan optimization environment variables for AMD focus
ENV VK_LAYER_PATH="/usr/share/vulkan/explicit_layer.d"
ENV VK_ICD_FILENAMES="/usr/share/vulkan/icd.d/radeon_icd.x86_64.json:/usr/share/vulkan/icd.d/intel_icd.x86_64.json:/usr/share/vulkan/icd.d/nvidia_icd.json"
ENV VULKAN_SDK="/usr"
ENV VK_LOADER_DEBUG="warn"
ENV VK_INSTANCE_LAYERS=""

# AMD-specific Vulkan and compute environment variables
ENV AMD_VULKAN_ICD="RADV"
ENV RADV_PERFTEST="aco,llvm"
ENV MESA_VK_VERSION_OVERRIDE="1.3"
ENV MESA_LOADER_DRIVER_OVERRIDE="radeonsi"

# Vulkan device environment for auto-detection (try all devices)
ENV GGML_VULKAN_DEVICE="0"
ENV GGML_VULKAN_CHECK_RESULTS="1"

# Additional debugging and forcing Vulkan
ENV VK_DRIVER_FILES="/usr/share/vulkan/icd.d/radeon_icd.x86_64.json"
ENV GGML_VULKAN_FORCE_INITIALIZATION="1"
ENV VK_LOADER_DRIVERS_SELECT="*radeon*"

# Force GGML to use Vulkan backend (bypass detection)
ENV GGML_VULKAN="1"
ENV GGML_FORCE_VULKAN="1"

# Expose the OpenAI-compatible server
EXPOSE 8080

# Copy all startup scripts
COPY scripts/ /app/scripts/
RUN chmod +x /app/scripts/*.sh && \
    find /app/scripts -name "*.sh" -exec sed -i 's/\r$//' {} \; && \
    find /app/scripts -name "*.sh" -exec dos2unix {} \;

# Dynamic startup script selection
# Override the official image's entrypoint to run our script
ENTRYPOINT ["/bin/bash"]
CMD ["-c", "/app/scripts/start-${MODEL_SCRIPT}.sh"]
