services:
  # AMD iGPU ROCm Base Container - Exact copy from Toxantron/iGPU-Docker
  rocm-igpu-base:
    image: rocm-igpu:latest
    build:
      context: .
      dockerfile: Dockerfile.rocm-base
    container_name: rocm-igpu-base
    # Device access for AMD iGPU - exactly as specified by Toxantron
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    # Group permissions for render and video groups
    group_add:
      - "${RENDER_GROUP_ID}"
      - "${VIDEO_GROUP_ID}"
    # Interactive shell
    stdin_open: true
    tty: true
    restart: unless-stopped

  # ROCm-enabled LLaMA.cpp Server with AMD iGPU Support
  rocm-llama-server:
    image: rocm-llama-server:latest
    build:
      context: .
      dockerfile: Dockerfile.rocm-llama-server
    container_name: rocm-llama-server
    depends_on:
      - rocm-igpu-base
    # Device access for AMD iGPU - exactly as specified by Toxantron
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    # Group permissions for render and video groups
    group_add:
      - "${RENDER_GROUP_ID}"
      - "${VIDEO_GROUP_ID}"
    environment:
      - MODEL_SCRIPT=mistral-small-3.2-24b-vision-rocm
      # ROCm environment from Toxantron repo
      - HSA_OVERRIDE_GFX_VERSION=11.0.2
      - HCC_AMDGPU_TARGET=gfx1103
      - ROCM_VERSION=6.4.1
    ports:
      - "8086:8080"
    volumes:
      - ${USERPROFILE:-~}/.cache/llama:/root/.cache/llama
    restart: unless-stopped
